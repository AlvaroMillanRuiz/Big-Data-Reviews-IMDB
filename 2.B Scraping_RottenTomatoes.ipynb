{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf463a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source = https://techpolicyinstitute.org/publications/miscellaneous/rotten-tomatoes-and-imdb-reviews-strongly-correlated-with-movie-revenues/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17c6d38",
   "metadata": {},
   "source": [
    "## Scraping Rottentomatoes: https://www.rottentomatoes.com/browse/movies_in_theaters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57923420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import duckdb\n",
    "from urllib import parse\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d90a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create fake user agents to use while requesting\n",
    "user_agents_list = [\n",
    "    'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c56cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_word(word):\n",
    "    \"\"\"\n",
    "    Strips a word from all punctuation, whitespace, and digits. Then converts the word into all lower case\n",
    "    and convert all characters with accents to non-accent letters.\n",
    "    \"\"\"\n",
    "    word = re.sub(r'[^\\w\\s]','',word).lower()\n",
    "    word = re.sub(r'[àáâãäå]', 'a', word)\n",
    "    word = re.sub(r'[èéêë]', 'e', word)\n",
    "    word = re.sub(r'[ìíîï]', 'i', word)\n",
    "    word = re.sub(r'[òóôõö]', 'o', word)\n",
    "    word = re.sub(r'[ùúûü]', 'u', word)\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e5542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_cleaned_strings(dfname, columnname):\n",
    "    \"\"\"\n",
    "    Maps new values in a df-column. From a new created dictionary, with as Key the 'old' string value and \n",
    "    as Value the 'new'-string value. The 'new'-string values are extracted with the function convert_word().\n",
    "    \"\"\"\n",
    "    dict_old_new = {}\n",
    "    for i in dfname[columnname]:\n",
    "        if type(i) != str:\n",
    "            continue\n",
    "        else:\n",
    "            dict_old_new[i] = convert_word(i)\n",
    "\n",
    "    dfname[columnname] = dfname[columnname].map(dict_old_new)\n",
    "    \n",
    "    return dfname[columnname]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f2a4b",
   "metadata": {},
   "source": [
    "### Get pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef91866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get request to the first page url\n",
    "url = 'https://www.rottentomatoes.com/browse/movies_at_home/?page=2'\n",
    "# url = \"https://www.rottentomatoes.com/browse/movies_at_home/?page=47\"\n",
    "\n",
    "r = requests.get(url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "# print(r.text)\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ccc5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pages id (after click load more button)\n",
    "urls = ['https://www.rottentomatoes.com/browse/movies_at_home/']\n",
    "url = 'https://www.rottentomatoes.com/browse/movies_at_home/'\n",
    "for count in range(2,100,1):                    ###### Don't know exactly how much there are?? try and check\n",
    "    count = '?page=' + str(count)\n",
    "    url = urljoin(url, count)\n",
    "    urls.append(url)\n",
    "# urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e24d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids for the movie pages (after click on movie)\n",
    "movie_pages = []\n",
    "pages = soup.find_all('a', attrs = {'data-qa':'discovery-media-list-item-caption'}) \n",
    "# print(pages)\n",
    "\n",
    "for p in pages:\n",
    "    link_id = p.get('href')\n",
    "    m_link = urljoin(url, link_id)\n",
    "#     print(m_link)\n",
    "    movie_pages.append(m_link)\n",
    "# movie_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97a5433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape info from movie pages\n",
    "\n",
    "#get request to an example movie page url\n",
    "url = 'https://www.rottentomatoes.com/m/tomorrows_hope'\n",
    "\n",
    "r = requests.get(url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "## get movie information (labels and values)\n",
    "# create empty df\n",
    "df_rot = pd.DataFrame()\n",
    "\n",
    "#Get labels\n",
    "label_col =[]\n",
    "labels = soup.find_all('b', attrs = {'data-qa': 'movie-info-item-label'})\n",
    "for l in labels:\n",
    "    label_col.append(l.text.strip())\n",
    "\n",
    "df_rot['labels'] = label_col\n",
    "# label_col\n",
    "\n",
    "#Get values of labels\n",
    "val =[]\n",
    "values = soup.find_all('span', attrs = {'data-qa': 'movie-info-item-value'})\n",
    "for v in values:\n",
    "    val.append(v.text.strip())\n",
    "    \n",
    "df_rot['val'] = val\n",
    "\n",
    "# val[2]\n",
    "# print(val)\n",
    "# print(labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4a2e2cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            \n",
      "                            Documentary\n",
      "                            \n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "# Scrape info from movie pages\n",
    "\n",
    "#get request to an example movie page url\n",
    "url = 'https://www.rottentomatoes.com/m/tomorrows_hope'\n",
    "\n",
    "r = requests.get(url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "## get movie information (labels and values)\n",
    "# create empty df\n",
    "df_rot = pd.DataFrame()\n",
    "d = dict()\n",
    "lab = {}\n",
    "\n",
    "#Get labels\n",
    "label_col =[]\n",
    "title = soup.find_all(class_=\"scoreboard__title\")\n",
    "# for i in title:\n",
    "#     print(i.text)\n",
    "labels = soup.find_all('b', attrs = {'data-qa': 'movie-info-item-label'})\n",
    "values = soup.find_all('span', attrs = {'class':'info-item-value','data-qa': 'movie-info-item-value'})\n",
    "# values2 = soup.find_all(class_=\"info-item-value\")\n",
    "\n",
    "# get values\n",
    "\n",
    "for k, v in enumerate(values):\n",
    "    for s in v:\n",
    "        print(s)\n",
    "    break\n",
    "\n",
    "#     d[k] = v.text.strip()\n",
    "# #         t.append([v.text])\n",
    "\n",
    "# d\n",
    "# # get labels\n",
    "# for i, l in enumerate(labels):\n",
    "#     df2 = df.assign(columns = [l.text.strip()])\n",
    "# df2\n",
    "#     lab[i] = l.text.strip()\n",
    "    \n",
    "# lab\n",
    "\n",
    "\n",
    "# t[1]\n",
    "\n",
    "# for l in labels:\n",
    "#     for v in values2:\n",
    "#         d[l.text.strip()] = v.text.strip()\n",
    "# d\n",
    "\n",
    "# df_rot['labels'] = label_col\n",
    "# label_col\n",
    "\n",
    "# #Get values of labels\n",
    "# val =[]\n",
    "# values = soup.find_all('span', attrs = {'data-qa': 'movie-info-item-value'})\n",
    "# for v in values:\n",
    "#     val.append(v.text.strip())\n",
    "    \n",
    "# df_rot['val'] = val\n",
    "\n",
    "# val[2]\n",
    "# print(val)\n",
    "# print(labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3db49eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas A. Morgan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tamra Raven, \\n                               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May 20, 2021\\n limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mar 21, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abramorama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         movie title\n",
       "0                                        Documentary\n",
       "1                                            English\n",
       "2                                   Thomas A. Morgan\n",
       "3  Tamra Raven, \\n                               ...\n",
       "4                             May 20, 2021\\n limited\n",
       "5                                       Mar 21, 2023\n",
       "6                                                45m\n",
       "7                                         Abramorama"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(d, orient='index', columns=['movie title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7639c47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genre:</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Original Language:</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Director:</td>\n",
       "      <td>Thomas A. Morgan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Producer:</td>\n",
       "      <td>Tamra Raven, \\n                               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Release Date (Theaters):</td>\n",
       "      <td>May 20, 2021\\n limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Release Date (Streaming):</td>\n",
       "      <td>Mar 21, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Runtime:</td>\n",
       "      <td>45m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Distributor:</td>\n",
       "      <td>Abramorama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      labels  \\\n",
       "0                     Genre:   \n",
       "1         Original Language:   \n",
       "2                  Director:   \n",
       "3                  Producer:   \n",
       "4   Release Date (Theaters):   \n",
       "5  Release Date (Streaming):   \n",
       "6                   Runtime:   \n",
       "7               Distributor:   \n",
       "\n",
       "                                                 val  \n",
       "0                                        Documentary  \n",
       "1                                            English  \n",
       "2                                   Thomas A. Morgan  \n",
       "3  Tamra Raven, \\n                               ...  \n",
       "4                             May 20, 2021\\n limited  \n",
       "5                                       Mar 21, 2023  \n",
       "6                                                45m  \n",
       "7                                         Abramorama  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571720bd",
   "metadata": {},
   "source": [
    "## Scraping all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "83e948ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/3k9f5xrj7wn3f78wkf2507280000gn/T/ipykernel_12635/1653547464.py:54: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  s1=pd.Series(titles,name='titles')\n",
      "/var/folders/p3/3k9f5xrj7wn3f78wkf2507280000gn/T/ipykernel_12635/1653547464.py:55: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  s2=pd.Series(lab_list,name='labels')\n",
      "/var/folders/p3/3k9f5xrj7wn3f78wkf2507280000gn/T/ipykernel_12635/1653547464.py:56: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  s3=pd.Series(val ,name='values')\n"
     ]
    }
   ],
   "source": [
    "### PUT IT ALL TOGETHER\n",
    "df = pd.DataFrame()\n",
    "lab_list = []\n",
    "titles = []\n",
    "val = []\n",
    "\n",
    "for url in movie_pages:\n",
    "    #get request to page\n",
    "    r = requests.get(url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "    \n",
    "    # request movie page from url\n",
    "    for u in urls:\n",
    "        req = requests.get(u, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "        soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "        \n",
    "#         print(soup.prettify())\n",
    "        ## get movie information (labels and values)\n",
    "\n",
    "        #Get title, labels and values\n",
    "        title = soup.find_all(class_=\"scoreboard__title\")\n",
    "        labels = soup.find_all('b', attrs = {'data-qa': 'movie-info-item-label'})\n",
    "        values = soup.find_all('span', attrs = {'class':'info-item-value','data-qa': 'movie-info-item-value'})\n",
    "        # values2 = soup.find_all(class_=\"info-item-value\")\n",
    "\n",
    "\n",
    "        # get labels and put them to the columns of the df\n",
    "        for lab in labels:\n",
    "            for l in lab:\n",
    "                lab_list.append(l)\n",
    "            df['labels'] = lab_list\n",
    "#             df2 = df.assign(columns = [l.text.strip()])\n",
    "#             lab[i] = l.text.strip()\n",
    "#             l_df = pd.DataFrame.from_dict(d, orient='index', columns=['movie title'])\n",
    "            \n",
    "    \n",
    "        # get title\n",
    "        for t in title:\n",
    "            titles.append(t.text)\n",
    "        df['title'] = titles\n",
    "            \n",
    "        # get values\n",
    "        for v in values:\n",
    "            val.append(v.text.strip())\n",
    "        df['values'] = val\n",
    "#             v_df = pd.DataFrame.from_dict(d, orient='index', columns=['movie title'])\n",
    "#             #join the labels df l_df\n",
    "#             l_df = l_df.join(v_df)\n",
    "        \n",
    "#         df_from_lists = pd.DataFrame(\n",
    "#             {'title': titles,\n",
    "#              'labels': lab_list,\n",
    "#              'values': val\n",
    "#             })\n",
    "        s1=pd.Series(titles,name='titles')\n",
    "        s2=pd.Series(lab_list,name='labels')\n",
    "        s3=pd.Series(val ,name='values')\n",
    "        \n",
    "        df2 = pd.concat([s1,s2,s3], axis=1)\n",
    "\n",
    "        val = []\n",
    "        titles = []\n",
    "        lab_list= []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cfed4d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>labels</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [titles, labels, values]\n",
       "Index: []"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a75d49f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "8 columns passed, passed data had 1 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0;31m# caller's responsibility to check for this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m             raise AssertionError(\n\u001b[0m\u001b[1;32m   1031\u001b[0m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 8 columns passed, passed data had 1 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p3/3k9f5xrj7wn3f78wkf2507280000gn/T/ipykernel_12635/1652347384.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mrot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m df = pd.DataFrame(rot, columns=['Genre:', 'Original Language:', 'Director:', 'Producer:',\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m'Release Date (Theaters):'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Release Date (Streaming):'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Runtime:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m 'Distributor:'])\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    719\u001b[0m                         \u001b[0;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[1;32m    722\u001b[0m                         \u001b[0;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                         \u001b[0;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m     \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 8 columns passed, passed data had 1 columns"
     ]
    }
   ],
   "source": [
    "# Scrape info from movie pages\n",
    "\n",
    "#get request to an example movie page url\n",
    "url = 'https://www.rottentomatoes.com/m/tomorrows_hope'\n",
    "\n",
    "r = requests.get(url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "## get movie information (labels and values)\n",
    "# create empty df with the columnnames\n",
    "df_rot = pd.DataFrame(columns = ['Genre:', 'Original Language:', 'Director:', 'Producer:',\n",
    "       'Release Date (Theaters):', 'Release Date (Streaming):', 'Runtime:',\n",
    "       'Distributor:'])\n",
    "rot = []\n",
    "\n",
    "#Get labels\n",
    "labels = soup.find_all('b', attrs = {'data-qa': 'movie-info-item-label'})\n",
    "values = soup.find_all('span', attrs = {'data-qa': 'movie-info-item-value'})\n",
    "\n",
    "for l in labels:\n",
    "    for v in values:\n",
    "        for item in [v.text]:\n",
    "            row = [str(item).strip()]\n",
    "            rot.append(row)\n",
    "df = pd.DataFrame(rot, columns=['Genre:', 'Original Language:', 'Director:', 'Producer:',\n",
    "'Release Date (Theaters):', 'Release Date (Streaming):', 'Runtime:',\n",
    "'Distributor:'])\n",
    "print(df)\n",
    "            \n",
    "      \n",
    "            \n",
    "            \n",
    "# #             print('1.',item)\n",
    "# #         print(v.text.strip())\n",
    "#             rot_dict[str(l.text).strip()] = (str(item).strip())\n",
    "# # print(rot_dict)\n",
    "#             df = pd.DataFrame([rot_dict])\n",
    "# #             df_rot = pd.concat([df_rot, df], ignore_index=True)\n",
    "# #             df_rot\n",
    "# rot_dict = {}\n",
    "\n",
    "\n",
    "# Insert row to the dataframe using DataFrame.append()\n",
    "# df = pd.DataFrame(technologies)\n",
    "# new_row = {'Courses':'Hyperion', 'Fee':24000, 'Duration':'55days', 'Discount':1800}\n",
    "# df2 = df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dbcac62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rot = df_rot.set_index('labels').T.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a7ac5aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Genre:', 'Original Language:', 'Director:', 'Producer:',\n",
       "       'Release Date (Theaters):', 'Release Date (Streaming):', 'Runtime:',\n",
       "       'Distributor:'],\n",
       "      dtype='object', name='labels')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next step is to add to dict or tuples and then to df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final step is when all above works as expected, put it all togheter and scrape every movie page of \n",
    "### every loaded page (load button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1377798",
   "metadata": {},
   "source": [
    "### Clean names so we can merge with the project data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016cd0ba",
   "metadata": {},
   "source": [
    "### Add as table to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb11d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "##to do\n",
    "# # create a connection to a file called 'imdb_reviews.db'\n",
    "# con = duckdb.connect('imdb_reviews.db')\n",
    "\n",
    "# # create a table and load data into it\n",
    "# con.sql(\"CREATE TABLE IF NOT EXISTS budget_data AS SELECT * FROM df\")\n",
    "\n",
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77270f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
